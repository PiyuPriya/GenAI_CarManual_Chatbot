{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ddaa30d-fadd-42ee-bc1c-8a9d3371f9f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_setup_environment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481e87fc-a1fb-4132-a650-c338ba72eb2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: Load, Chunk, and Save Manuals\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c887fa2-15b3-4f40-838f-cbb833c7be30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and extract text from PDF\n",
    "def load_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    return \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "\n",
    "# Function to chunk text\n",
    "def chunk_text(text, language, source):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.create_documents([text])\n",
    "    return [{\n",
    "        \"text\": doc.page_content,\n",
    "        \"language\": language,\n",
    "        \"source\": source\n",
    "    } for doc in chunks]\n",
    "\n",
    "# Paths\n",
    "manual_base = \"/Workspace/Users/pbmarihal3929@gmail.com/GenAI_CarManual_Chatbot_Repo/manuals\"\n",
    "english_path = f\"{manual_base}/a4-2025-owners-manual.pdf\"\n",
    "german_path = f\"{manual_base}/a4-2025-betriebsanleitung.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90fcd199-4f70-421f-8b56-0e2ad04b7e2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load and chunk\n",
    "english_chunks = chunk_text(load_pdf_text(english_path), \"English\", \"a4-2025-owners-manual.pdf\")\n",
    "german_chunks = chunk_text(load_pdf_text(german_path), \"German\", \"a4-2025-betriebsanleitung.pdf\")\n",
    "\n",
    "# Combine and create Spark DataFrame\n",
    "all_chunks = english_chunks + german_chunks\n",
    "schema = StructType([\n",
    "    StructField(\"text\", StringType(), True),\n",
    "    StructField(\"language\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(all_chunks, schema=schema)\n",
    "\n",
    "# Save to Unity Catalog volume (or use DBFS if needed)\n",
    "output_path = \"/Volumes/genai_catalog/car_manuals/manual_chunks/chunks_delta\"\n",
    "df.write.mode(\"overwrite\").format(\"delta\").save(output_path)\n",
    "\n",
    "print(f\"Saved {df.count()} chunks to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9681632c-3410-4dfe-ad3d-23e98037a7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Data_Loading_and_Chunking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
